{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **MLP Model** (Iris)\n",
        "**Sequential API**"
      ],
      "metadata": {
        "id": "t2UJJdQ-YXrO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaBStEkGMeO-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import BatchNormalization,Conv2D,Dense,LSTM,Dropout,Input\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris, load_digits\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "y = to_categorical(y) ##One hot encoding of Y\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.3)\n",
        "scaler = StandardScaler().fit(X_train) #Fit a scaler for \n",
        "X_train_scaled = scaler.transform(X_train) #Transform training data\n",
        "X_test_scaled = scaler.transform(X_test) #Transform testing data"
      ],
      "metadata": {
        "id": "mxaIcr45X4Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_shape=(4,), activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "                      optimizer='adam', \n",
        "                      metrics=['accuracy'])\n",
        "hist = model.fit(X_train_scaled,y_train,validation_data=(X_test_scaled,y_test),epochs=15)"
      ],
      "metadata": {
        "id": "s_MeggauM8F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functional API**"
      ],
      "metadata": {
        "id": "t4IOTY99iBsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input((4,))\n",
        "x = Dense(32, activation='relu')(input)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=[input],outputs=[output])\n",
        "model.summary()\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "                      optimizer='adam', \n",
        "                      metrics=['accuracy'])\n",
        "hist = model.fit(X_train_scaled,y_train,validation_data=(X_test_scaled,y_test),epochs=15)"
      ],
      "metadata": {
        "id": "KZbxIRNMf_3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AIoo_oFSgMzw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}