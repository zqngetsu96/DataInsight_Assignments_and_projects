{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7877095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hamza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fcc760",
   "metadata": {},
   "source": [
    "## I- Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464d3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I were to ask you what's the different        between \"Word\" and \"word\" in terms of understanding _-_-_-_the word, chances are you'd say they're-- the same thing--. To a machine that doesn't *understand.. words, they aren't the same.  One way to circumvent this is to simply ensure that all text is fed to the transformation steps as lowercase text only. This step helps eliminate any redundancy in words. To achieve this, this sample code is more than enough\n"
     ]
    }
   ],
   "source": [
    "text = \"If I were to ask you what's the different        between \\\"Word\\\" and \\\"word\\\" \\\n",
    "in terms of understanding _-_-_-_the word, chances are you'd say they're-- the same thing--. To a machine that doesn't *understand.. words, they aren't the same.  One way to circumvent this is to simply ensure that all text is fed to the transformation steps as lowercase text only. This step helps eliminate any redundancy in words. To achieve this, this sample code is more than enough\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab19048",
   "metadata": {},
   "source": [
    "### 1- Text lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69a796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if i were to ask you what's the different        between \"word\" and \"word\" in terms of understanding _-_-_-_the word, chances are you'd say they're-- the same thing--. to a machine that doesn't *understand.. words, they aren't the same.  one way to circumvent this is to simply ensure that all text is fed to the transformation steps as lowercase text only. this step helps eliminate any redundancy in words. to achieve this, this sample code is more than enough\n"
     ]
    }
   ],
   "source": [
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efcd4f",
   "metadata": {},
   "source": [
    "### 2- Removing punctuation (Regex matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a77fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "if i were to ask you whats the different        between word and word in terms of understanding the word chances are youd say theyre the same thing to a machine that doesnt understand words they arent the same  one way to circumvent this is to simply ensure that all text is fed to the transformation steps as lowercase text only this step helps eliminate any redundancy in words to achieve this this sample code is more than enough\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "no_punct_text= re.sub(r'['+string.punctuation+']', '', text.lower())\n",
    "print(no_punct_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44dcc7",
   "metadata": {},
   "source": [
    "### 3- Removing extra spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3887d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if i were to ask you whats the different between word and word in terms of understanding the word chances are youd say theyre the same thing to a machine that doesnt understand words they arent the same one way to circumvent this is to simply ensure that all text is fed to the transformation steps as lowercase text only this step helps eliminate any redundancy in words to achieve this this sample code is more than enough\n"
     ]
    }
   ],
   "source": [
    "no_extra_space = re.sub(' +',' ',no_punct_text)\n",
    "print(no_extra_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f7ce4",
   "metadata": {},
   "source": [
    "### 4- Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "798bf266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stopword = stopwords.words('english')\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231721d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask whats different word word terms understanding word chances youd say theyre thing machine doesnt understand words arent one way circumvent simply ensure text fed transformation steps lowercase text step helps eliminate redundancy words achieve sample code enough\n"
     ]
    }
   ],
   "source": [
    "new_text = \" \".join([word for word in str(no_extra_space.lower()).split() if word not in stopword])\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3229d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_clean(row):\n",
    "    row = \" \".join([word for word in str(row.lower()).split() if word not in stopword])\n",
    "    row = re.sub(r'['+string.punctuation+']', '', row)\n",
    "    no_extra_space = re.sub(' +',' ',row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1e3d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask whats different word word terms understanding the word chances say theyre thing machine understand words same one way circumvent simply ensure text fed transformation steps lowercase text only step helps eliminate redundancy words achieve this sample code enough\n"
     ]
    }
   ],
   "source": [
    "final_text = final_clean(text)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bdee3a",
   "metadata": {},
   "source": [
    "## II-Text transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321f5519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Inaugural Address</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>First Inaugural Address</td>\n",
       "      <td>Thursday, April 30, 1789</td>\n",
       "      <td>Fellow-Citizens of the Senate and of the House...</td>\n",
       "      <td>fellowcitizens senate house representatives am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>Second Inaugural Address</td>\n",
       "      <td>Monday, March 4, 1793</td>\n",
       "      <td>Fellow Citizens:  I AM again called upon by th...</td>\n",
       "      <td>fellow citizens called upon voice country exec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Adams</td>\n",
       "      <td>Inaugural Address</td>\n",
       "      <td>Saturday, March 4, 1797</td>\n",
       "      <td>WHEN it was first perceived, in early times, t...</td>\n",
       "      <td>first perceived early times middle course amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>First Inaugural Address</td>\n",
       "      <td>Wednesday, March 4, 1801</td>\n",
       "      <td>Friends and Fellow-Citizens:  CALLED upon to u...</td>\n",
       "      <td>friends fellowcitizens called upon undertake d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>Second Inaugural Address</td>\n",
       "      <td>Monday, March 4, 1805</td>\n",
       "      <td>PROCEEDING, fellow-citizens, to that qualifica...</td>\n",
       "      <td>proceeding fellowcitizens qualification consti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name         Inaugural Address                      Date  \\\n",
       "0  George Washington   First Inaugural Address  Thursday, April 30, 1789   \n",
       "1  George Washington  Second Inaugural Address     Monday, March 4, 1793   \n",
       "2         John Adams         Inaugural Address   Saturday, March 4, 1797   \n",
       "3   Thomas Jefferson   First Inaugural Address  Wednesday, March 4, 1801   \n",
       "4   Thomas Jefferson  Second Inaugural Address     Monday, March 4, 1805   \n",
       "\n",
       "                                                text  \\\n",
       "0  Fellow-Citizens of the Senate and of the House...   \n",
       "1  Fellow Citizens:  I AM again called upon by th...   \n",
       "2  WHEN it was first perceived, in early times, t...   \n",
       "3  Friends and Fellow-Citizens:  CALLED upon to u...   \n",
       "4  PROCEEDING, fellow-citizens, to that qualifica...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  fellowcitizens senate house representatives am...  \n",
       "1  fellow citizens called upon voice country exec...  \n",
       "2  first perceived early times middle course amer...  \n",
       "3  friends fellowcitizens called upon undertake d...  \n",
       "4  proceeding fellowcitizens qualification consti...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_csv('inaugural_speeches.csv')\n",
    "\n",
    "text_df['clean_text'] = text_df['text'].apply(lambda row: final_clean(row))\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a15370",
   "metadata": {},
   "source": [
    "### 1- Word Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2210f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandon', 'abiding', 'ability', 'able', 'abroad', 'absolute', 'abuse', 'abuses', 'accept', 'accepted', 'accomplish', 'accomplished', 'accomplishment', 'accordance', 'according', 'account', 'accountability', 'achieve', 'achieved', 'achievement', 'achievements', 'acknowledge', 'acknowledged', 'acquiescence', 'act', 'acted', 'acting', 'action', 'actions', 'acts', 'actual', 'adapted', 'add', 'added', 'additional', 'address', 'adequate', 'adjust', 'adjustment', 'administer', 'administered', 'administration', 'administration government', 'administrations', 'admitted', 'adopt', 'adopted', 'adoption', 'advance', 'advanced', 'advancement', 'advancing', 'advantage', 'advantages', 'affairs', 'affect', 'affecting', 'affection', 'afford', 'afforded', 'age', 'agencies', 'agents', 'ages', 'aggression', 'ago', 'agree', 'agricultural', 'agriculture', 'agriculture commerce', 'aid', 'aids', 'aim', 'alike', 'alliances', 'allies', 'allow', 'allowed', 'almighty', 'almighty god', 'altogether', 'ambition', 'amendment', 'america', 'american', 'american people', 'americans', 'americas', 'americau0092s', 'amity', 'ample', 'ancient', 'anew', 'animosities', 'answer', 'anticipated', 'anxiety', 'anxious', 'appeal', 'appear', 'application', 'apply', 'appointed', 'appointment', 'apprehension', 'approach', 'approaching', 'approbation', 'appropriate', 'approved', 'arbitration', 'ardent', 'arduous', 'argument', 'arise', 'arisen', 'armaments', 'armed', 'armies', 'arms', 'army', 'arrangement', 'arrangements', 'articles', 'arts', 'ask', 'asked', 'aspirations', 'assembled', 'assembly', 'assigned', 'assistance', 'associated', 'assume', 'assumed', 'assurance', 'assure', 'assured', 'atlantic', 'attack', 'attain', 'attained', 'attempt', 'attention', 'author', 'authorities', 'authority', 'avail', 'avoid', 'away', 'bad', 'balance', 'based', 'basic', 'basis', 'battle', 'bear', 'bearing', 'began', 'begin', 'beginning', 'begun', 'behalf', 'belief', 'believe', 'believed', 'belong', 'belongs', 'beloved', 'beloved country', 'beneficent', 'benefit', 'benefits', 'benign', 'best', 'best ability', 'best interests', 'bestowed', 'better', 'bind', 'birth', 'bitter', 'bless', 'blessed', 'blessing', 'blessings', 'blood', 'body', 'bold', 'boldly', 'bonds', 'born', 'borne', 'bound', 'boundaries', 'branch', 'branch government', 'branches', 'branches government', 'brave', 'break', 'brief', 'briefly', 'bright', 'bring', 'broad', 'brought', 'build', 'building', 'built', 'bulwark', 'burden', 'burdens', 'bush', 'business', 'calculated', 'called', 'calling', 'calls', 'came', 'candid', 'candor', 'capable', 'capacity', 'capital', 'care', 'career', 'careful', 'carefully', 'carried', 'carry', 'carrying', 'case', 'cases', 'cast', 'cause', 'causes', 'cease', 'celebrate', 'celebration', 'central', 'centuries', 'century', 'ceremony', 'certain', 'certainly', 'challenge', 'challenges', 'chance', 'change', 'changed', 'changes', 'character', 'charge', 'charged', 'charity', 'cheerfully', 'cherish', 'cherished', 'chief', 'chief executive', 'chief justice', 'chief magistrate', 'child', 'children', 'choice', 'choices', 'choose', 'chosen', 'circumstances', 'cities', 'citizen', 'citizens', 'citizenship', 'city', 'civil', 'civil war', 'civilization', 'civilized', 'claim', 'claims', 'class', 'clear', 'clearly', 'climate', 'close', 'combinations', 'come', 'comes', 'comfort', 'coming', 'command', 'commerce', 'commercial', 'commitment', 'committed', 'common', 'common country', 'common good', 'communism', 'communities', 'community', 'competent', 'competition', 'complete', 'compromise', 'conception', 'concern', 'concerned', 'concerning', 'concerns', 'concession', 'conclusion', 'condition', 'conditions', 'conduct', 'conducted', 'confederacy', 'confederation', 'conferred', 'confidence', 'confident', 'confidently', 'conflict', 'conflicting', 'conformity', 'confront', 'congress', 'connected', 'conquered', 'conscience', 'conscious', 'consciousness', 'consent', 'consequence', 'consequences', 'consequent', 'consider', 'consideration', 'considerations', 'considered', 'consistent', 'constant', 'constantly', 'constitute', 'constituted', 'constitution', 'constitution laws', 'constitution united', 'constitution united states', 'constitutional', 'construction', 'contemplate', 'contest', 'continent', 'continents', 'continuance', 'continue', 'continued', 'continuing', 'contrary', 'contributed', 'control', 'controlled', 'controversies', 'convenience', 'conviction', 'convictions', 'cooperation', 'coordinate', 'correct', 'cost', 'councils', 'counsel', 'counsels', 'count', 'countries', 'country', 'countrymen', 'countrys', 'courage', 'course', 'court', 'create', 'created', 'credit', 'creed', 'crime', 'crisis', 'cultivate', 'currency', 'current', 'custom', 'cut', 'daily', 'danger', 'dangerous', 'dangers', 'dare', 'dark', 'darkness', 'day', 'days', 'dealing', 'dear', 'death', 'debate', 'debt', 'debts', 'decades', 'decency', 'decent', 'decide', 'decision', 'decisions', 'decisive', 'declaration', 'declaration independence', 'declare', 'declared', 'decline', 'dedication', 'deemed', 'deep', 'deeper', 'deeply', 'defeat', 'defend', 'defend constitution', 'defend constitution united', 'defense', 'deficit', 'define', 'degree', 'delayed', 'demand', 'demanded', 'demands', 'democracy', 'democratic', 'denied', 'deny', 'department', 'departments', 'departure', 'depend', 'depends', 'depression', 'derived', 'deserve', 'desire', 'despotism', 'destinies', 'destiny', 'destroy', 'destruction', 'destructive', 'determination', 'determine', 'determined', 'developed', 'developing', 'development', 'devoted', 'devotion', 'dictates', 'difference', 'difference opinion', 'differences', 'different', 'difficult', 'difficulties', 'difficulty', 'dignity', 'diplomacy', 'direct', 'directed', 'direction', 'directly', 'disaster', 'discharge', 'discharge duties', 'discipline', 'discord', 'discussion', 'disease', 'disposition', 'disputes', 'disregard', 'dissolution', 'distant', 'distinct', 'distinction', 'distinguished', 'distrust', 'disturb', 'disturbed', 'diversity', 'divide', 'divided', 'divine', 'division', 'divisions', 'does', 'domestic', 'doubt', 'drawn', 'dream', 'dreams', 'duration', 'duties', 'duty', 'early', 'earnest', 'earnestly', 'earth', 'ease', 'easily', 'east', 'easy', 'economic', 'economy', 'economy public', 'education', 'effect', 'effective', 'effects', 'efficiency', 'efficient', 'effort', 'efforts', 'elected', 'election', 'elections', 'element', 'elements', 'embarrassment', 'embrace', 'emergency', 'employed', 'employment', 'enable', 'enabled', 'encourage', 'encouraged', 'encouragement', 'encouraging', 'end', 'endanger', 'endeavor', 'endowed', 'ends', 'endure', 'enduring', 'enemies', 'enemy', 'energies', 'energy', 'enforce', 'enforced', 'enforcement', 'engage', 'engaged', 'enjoy', 'enjoyed', 'enjoyment', 'enlarged', 'enlightened', 'ensure', 'enter', 'entered', 'entering', 'enterprise', 'enterprises', 'entertain', 'entertained', 'entire', 'entirely', 'entitled', 'equal', 'equality', 'equally', 'equitable', 'era', 'error', 'errors', 'especially', 'essential', 'establish', 'established', 'establishment', 'eternal', 'europe', 'european', 'event', 'events', 'evidence', 'evil', 'evils', 'exact', 'exalted', 'example', 'examples', 'excited', 'excitement', 'exclusively', 'execute', 'executed', 'execution', 'executive', 'exercise', 'exercised', 'exist', 'existed', 'existence', 'existing', 'exists', 'expansion', 'expect', 'expectations', 'expected', 'expedient', 'expenditure', 'expenditures', 'expense', 'experience', 'experiment', 'express', 'expressed', 'expression', 'extend', 'extended', 'extension', 'extent', 'extraordinary', 'eyes', 'face', 'faces', 'facilities', 'fact', 'factories', 'factory', 'facts', 'faculties', 'fail', 'failed', 'failure', 'fair', 'faith', 'faithful', 'faithfully', 'fall', 'fallen', 'false', 'families', 'family', 'far', 'farm', 'farms', 'fate', 'father', 'father country', 'fathers', 'favor', 'favorable', 'favored', 'fear', 'fearless', 'fears', 'federal', 'federal government', 'feed', 'feel', 'feeling', 'feelings', 'fellow', 'fellow americans', 'fellow citizens', 'fellowcitizens', 'felt', 'fervent', 'fidelity', 'field', 'fight', 'final', 'finally', 'financial', 'firm', 'firmness', 'fitness', 'fixed', 'flag', 'flow', 'follow', 'followed', 'following', 'forbearance', 'force', 'forced', 'forces', 'forefathers', 'foreign', 'foreign nations', 'forever', 'forget', 'forgotten', 'form', 'form government', 'formation', 'formed', 'formidable', 'forms', 'forth', 'fortunate', 'fortunately', 'fortunes', 'forward', 'foster', 'fought', 'foundation', 'foundations', 'founded', 'founders', 'founding', 'free', 'free government', 'free people', 'freedom', 'freely', 'freemen', 'friend', 'friendly', 'friends', 'friendship', 'friendship nations', 'frontiers', 'fruitful', 'fruits', 'fulfill', 'fulfilled', 'fulfillment', 'fully', 'functions', 'fundamental', 'future', 'future generations', 'gained', 'gather', 'gave', 'general', 'general government', 'generally', 'generation', 'generations', 'generosity', 'generous', 'genius', 'gift', 'given', 'gives', 'giving', 'globe', 'glory', 'goal', 'god', 'god bless', 'gods', 'gold', 'gone', 'good', 'good faith', 'good government', 'goodness', 'govern', 'governed', 'government', 'government people', 'government shall', 'governments', 'gracious', 'grand', 'granted', 'grateful', 'gratitude', 'grave', 'great nation', 'great people', 'great small', 'greater', 'greatest', 'greatly', 'greatness', 'ground', 'group', 'growing', 'grown', 'growth', 'guarantees', 'guaranty', 'guard', 'guidance', 'guide', 'guided', 'habits', 'half', 'half century', 'hand', 'hands', 'happily', 'happiness', 'happy', 'hard', 'harmony', 'heal', 'health', 'hear', 'heard', 'heart', 'hearts', 'heaven', 'heavy', 'held', 'help', 'helped', 'hemisphere', 'heretofore', 'heritage', 'heroes', 'high', 'higher', 'highest', 'historic', 'history', 'hitherto', 'hold', 'holds', 'home', 'home abroad', 'homes', 'honest', 'honestly', 'honesty', 'honor', 'honorable', 'honored', 'hope', 'hoped', 'hopes', 'hostile', 'hour', 'house', 'human', 'human dignity', 'human life', 'humane', 'humanity', 'humble', 'humbly', 'humility', 'idea', 'ideal', 'idealism', 'ideals', 'ideas', 'ignorance', 'ignorant', 'illustrious', 'immediate', 'immigration', 'imperative', 'importance', 'important', 'impose', 'imposed', 'imposes', 'impossible', 'impressed', 'improve', 'improvement', 'inauguration', 'incident', 'including', 'increase', 'increased', 'increasing', 'independence', 'independent', 'indian', 'indispensable', 'individual', 'individuals', 'indulgence', 'industrial', 'industries', 'industry', 'inevitable', 'inflict', 'influence', 'influences', 'information', 'inhabitants', 'inheritance', 'initiative', 'injuries', 'injurious', 'injury', 'injustice', 'inseparable', 'insist', 'inspire', 'inspired', 'instance', 'instances', 'instead', 'institution', 'institutions', 'instruction', 'instrument', 'instrumentality', 'instruments', 'insure', 'integrity', 'intellectual', 'intelligence', 'intelligent', 'intended', 'intentions', 'intercourse', 'interests', 'interfere', 'interference', 'interior', 'internal', 'international', 'intrusted', 'invasion', 'invested', 'invite', 'invoke', 'involve', 'involved', 'involves', 'issue', 'issues', 'job', 'join', 'journey', 'judge', 'judgment', 'judicial', 'jurisdiction', 'just', 'justice', 'justly', 'keeping', 'kept', 'kind', 'knew', 'know', 'knowing', 'knowledge', 'known', 'labor', 'labors', 'laid', 'land', 'lands', 'language', 'large', 'largely', 'larger', 'lasting', 'lasting peace', 'late', 'lately', 'law', 'lawabiding', 'lawful', 'laws', 'lay', 'lead', 'leaders', 'leadership', 'leading', 'leads', 'learn', 'learned', 'leave', 'led', 'left', 'legal', 'legislation', 'legislative', 'legislature', 'legitimate', 'length', 'lesson', 'lessons', 'let', 'liberal', 'liberties', 'liberty', 'lies', 'life', 'lift', 'light', 'like', 'likely', 'limit', 'limitation', 'limitations', 'limited', 'limits', 'line', 'lines', 'little', 'live', 'lives', 'living', 'local', 'long', 'longer', 'look', 'looked', 'looking', 'lord', 'lose', 'loss', 'lost', 'lot', 'love', 'love liberty', 'loyalty', 'magistrate', 'magnitude', 'maintain', 'maintained', 'maintaining', 'maintenance', 'majority', 'make', 'makes', 'making', 'man', 'manage', 'manifest', 'mankind', 'manner', 'mans', 'manufactures', 'march', 'mark', 'marked', 'market', 'markets', 'marks', 'mass', 'master', 'material', 'materials', 'matter', 'matters', 'mean', 'meaning', 'means', 'measure', 'measures', 'meet', 'meeting', 'member', 'members', 'men', 'men women', 'menace', 'mercy', 'mere', 'merely', 'merit', 'met', 'method', 'methods', 'middle', 'midst', 'mighty', 'military', 'militia', 'millions', 'mind', 'mindful', 'minds', 'minorities', 'mission', 'mode', 'modern', 'moment', 'money', 'months', 'moral', 'motive', 'motives', 'mountains', 'moved', 'movement', 'moving', 'mr', 'mr chief', 'mr chief justice', 'mutual', 'narrow', 'nation people', 'national', 'national debt', 'national government', 'national life', 'nations earth', 'nations world', 'native', 'natural', 'nature', 'naval', 'navy', 'near', 'nearly', 'necessarily', 'necessary', 'necessities', 'necessity', 'need', 'needed', 'needs', 'negotiation', 'neighbors', 'neutrality', 'new', 'new states', 'new world', 'night', 'noble', 'north', 'north south', 'number', 'numbers', 'oath', 'oath office', 'oath taken', 'obedience', 'object', 'objects', 'obligation', 'obligations', 'observance', 'observe', 'observed', 'obvious', 'occasion', 'occurred', 'ocean', 'offer', 'office', 'office president', 'officer', 'officers', 'offices', 'official', 'old', 'ones', 'onward', 'open', 'opened', 'opening', 'operation', 'opinion', 'opinions', 'opportunities', 'opportunity', 'opposed', 'opposition', 'oppression', 'order', 'orderly', 'ordinary', 'organization', 'organized', 'original', 'ought', 'pacific', 'paid', 'parallel', 'partial', 'participation', 'particular', 'parties', 'partisan', 'parts', 'party', 'pass', 'passed', 'passing', 'passion', 'past', 'past years', 'path', 'patient', 'patriotic', 'patriotism', 'patriots', 'pay', 'peace', 'peace nations', 'peace world', 'peaceful', 'peculiar', 'people united', 'people united states', 'people world', 'peoples', 'perfect', 'perfection', 'perform', 'performance', 'perils', 'period', 'permanent', 'permit', 'permitted', 'perpetual', 'perpetuate', 'person', 'personal', 'persons', 'physical', 'place', 'placed', 'places', 'plain', 'plan', 'planet', 'plans', 'play', 'pledge', 'pledged', 'pledges', 'point', 'points', 'policies', 'policy', 'policy government', 'political', 'political parties', 'politics', 'poor', 'popular', 'population', 'portion', 'portions', 'position', 'possess', 'possessed', 'possibility', 'possible', 'posterity', 'poverty', 'power', 'powerful', 'powers', 'practicable', 'practical', 'practice', 'pray', 'prayer', 'prayers', 'precious', 'predecessor', 'predecessors', 'prejudice', 'prejudices', 'prepared', 'prescribed', 'presence', 'present', 'presented', 'preservation', 'preserve', 'preserve protect', 'preserve protect defend', 'preserved', 'preserving', 'president', 'president bush', 'president united', 'president united states', 'presidential', 'press', 'prevail', 'prevent', 'price', 'prices', 'pride', 'principal', 'principle', 'principles', 'private', 'privilege', 'privileges', 'problem', 'problems', 'proceed', 'proceeding', 'process', 'proclaim', 'produce', 'produced', 'production', 'productions', 'productive', 'products', 'profit', 'profound', 'program', 'progress', 'promise', 'promises', 'promote', 'promoted', 'promotion', 'prompt', 'promptly', 'proof', 'proper', 'properly', 'property', 'propose', 'proposed', 'prospect', 'prosper', 'prosperity', 'prosperous', 'protect', 'protect defend', 'protect defend constitution', 'protected', 'protecting', 'protection', 'proud', 'prove', 'proved', 'provide', 'provided', 'providence', 'provision', 'provisions', 'public', 'public debt', 'public expenditures', 'public money', 'public opinion', 'public private', 'public servants', 'public service', 'punishment', 'purpose', 'purposes', 'pursue', 'pursued', 'pursuit', 'pursuits', 'putting', 'quarter', 'question', 'questions', 'quiet', 'race', 'raise', 'raised', 'rapid', 'reach', 'reached', 'read', 'ready', 'real', 'reality', 'realize', 'realized', 'reason', 'reasonable', 'reasons', 'recall', 'receive', 'received', 'recent', 'recently', 'recognition', 'recognize', 'recognized', 'recommend', 'recommendations', 'recommended', 'redemption', 'reduce', 'reduced', 'reduction', 'reference', 'reflect', 'reform', 'regard', 'regard rights', 'regular', 'reject', 'relation', 'relations', 'reliance', 'relief', 'relieve', 'religion', 'religious', 'religious liberty', 'rely', 'relying', 'remain', 'remains', 'remedies', 'remedy', 'remember', 'remembered', 'remove', 'removed', 'render', 'renew', 'renewed', 'repeat', 'replace', 'representative', 'representatives', 'republic', 'republican', 'republics', 'require', 'required', 'requires', 'requisite', 'reserved', 'resist', 'resolution', 'resolve', 'resolved', 'resort', 'resource', 'resources', 'respect', 'respected', 'respective', 'respects', 'responsibilities', 'responsibility', 'responsible', 'rest', 'restoration', 'restore', 'restored', 'rests', 'result', 'results', 'retirement', 'return', 'revenue', 'revenues', 'reverence', 'reverently', 'reverse', 'revolution', 'revolutionary', 'reward', 'rewards', 'rich', 'right', 'rightful', 'rights', 'rise', 'rivers', 'road', 'roads', 'role', 'rule', 'rules', 'run', 'sacred', 'sacredly', 'sacrifice', 'sacrifices', 'safe', 'safely', 'safety', 'said', 'sanction', 'sanctioned', 'satisfaction', 'satisfactory', 'save', 'saw', 'say', 'scarcely', 'scheme', 'schools', 'science', 'sea', 'search', 'seas', 'second', 'section', 'section country', 'sectional', 'sections', 'secure', 'secured', 'securing', 'security', 'seek', 'seeking', 'seeks', 'seen', 'selected', 'selfgovernment', 'selfish', 'senate', 'sense', 'sentiment', 'sentiments', 'separate', 'seriously', 'servant', 'servants', 'serve', 'served', 'service', 'services', 'session', 'set', 'settled', 'settlement', 'shall', 'shall continue', 'shall endeavor', 'shape', 'share', 'shared', 'shores', 'short', 'shown', 'shrink', 'sick', 'sides', 'simple', 'single', 'situation', 'size', 'skill', 'slave', 'slavery', 'small', 'social', 'society', 'soil', 'soldiers', 'sole', 'solemn', 'solemn oath', 'solicitude', 'solution', 'solve', 'soon', 'sought', 'soul', 'sound', 'source', 'sources', 'south', 'southern', 'sovereign', 'sovereignty', 'speak', 'speaker', 'speaking', 'special', 'sphere', 'spirit', 'spiritual', 'spoke', 'spoken', 'spread', 'stability', 'stand', 'standard', 'standards', 'standing', 'stars', 'state', 'state governments', 'states', 'states people', 'statesmen', 'station', 'steadily', 'step', 'steps', 'stood', 'stop', 'storm', 'strangers', 'strength', 'strengthen', 'strengthened', 'strict', 'strictly', 'strife', 'striking', 'strive', 'strong', 'stronger', 'strongest', 'strongly', 'structure', 'struggle', 'struggling', 'subject', 'subjects', 'submit', 'submitted', 'succeed', 'success', 'successful', 'successfully', 'suffer', 'suffered', 'suffering', 'sufficient', 'suffrage', 'suffrages', 'suggest', 'sum', 'superior', 'supervision', 'supply', 'support', 'supported', 'supreme', 'sure', 'surely', 'surest', 'surplus', 'surrender', 'suspicion', 'sustain', 'sustained', 'swift', 'sword', 'sympathy', 'systems', 'taken', 'taking', 'talents', 'tariff', 'task', 'tasks', 'taught', 'tax', 'taxation', 'taxes', 'teach', 'temporary', 'tend', 'tendency', 'tens', 'term', 'terms', 'territorial', 'territories', 'territory', 'terror', 'test', 'th', 'thank', 'thank god', 'theory', 'thing', 'things', 'think', 'thought', 'thoughts', 'thousand', 'thousands', 'threat', 'threaten', 'threatened', 'threatening', 'ties', 'time come', 'time history', 'time peace', 'timeless', 'times', 'title', 'today', 'toil', 'told', 'tolerance', 'tomorrow', 'total', 'trade', 'tranquillity', 'transportation', 'treasury', 'treated', 'treaties', 'treaty', 'trial', 'tribunal', 'tried', 'triumph', 'triumphs', 'true', 'truly', 'trust', 'truth', 'truths', 'try', 'trying', 'turn', 'turning', 'tyranny', 'ultimate', 'ultimately', 'understand', 'understanding', 'understood', 'undertake', 'undertaken', 'unequal', 'union', 'union states', 'unite', 'united', 'united states', 'unity', 'universal', 'unless', 'unnecessary', 'unwilling', 'uphold', 'urge', 'urged', 'urgent', 'use', 'used', 'useful', 'utmost', 'valuable', 'value', 'values', 'varied', 'various', 'vast', 'verdict', 'vice', 'vice president', 'victory', 'view', 'views', 'vigor', 'violate', 'violation', 'violence', 'virtue', 'virtues', 'virtuous', 'vision', 'vital', 'voice', 'voices', 'vote', 'walk', 'want', 'wants', 'war', 'wars', 'washington', 'waste', 'way', 'way life', 'ways', 'weak', 'weakened', 'weakness', 'wealth', 'weapons', 'weight', 'welcome', 'welfare', 'wellbeing', 'west', 'western', 'whilst', 'white', 'wholesome', 'wholly', 'wide', 'willing', 'win', 'wisdom', 'wise', 'wisely', 'wish', 'wishes', 'witness', 'witnessed', 'women', 'word', 'words', 'work', 'working', 'works', 'world', 'worlds', 'worthy', 'write', 'written', 'wrong', 'year', 'years', 'years ago', 'yes', 'yield', 'young', 'zeal', 'zealously']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "cv = CountVectorizer(min_df=0.1,max_df=0.9,stop_words='english',ngram_range=(1,3)) #Instantiate the Count Vectorizer\n",
    "\n",
    "# Fit the vectorizer\n",
    "cv.fit(text_df['clean_text'])\n",
    "cv_transformed = cv.transform(text_df['clean_text']) #Transform the data into an array of word counts array\n",
    "cv_array = cv_transformed.toarray() #Create numpy array of the values\n",
    "# Print feature names\n",
    "print(cv.get_feature_names()) #Get the list of the counted(relevant) words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03cc9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(cv_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6937832c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word_c_abandon</th>\n",
       "      <th>Word_c_abiding</th>\n",
       "      <th>Word_c_ability</th>\n",
       "      <th>Word_c_able</th>\n",
       "      <th>Word_c_abroad</th>\n",
       "      <th>Word_c_absolute</th>\n",
       "      <th>Word_c_abuse</th>\n",
       "      <th>Word_c_abuses</th>\n",
       "      <th>Word_c_accept</th>\n",
       "      <th>Word_c_accepted</th>\n",
       "      <th>...</th>\n",
       "      <th>Word_c_written</th>\n",
       "      <th>Word_c_wrong</th>\n",
       "      <th>Word_c_year</th>\n",
       "      <th>Word_c_years</th>\n",
       "      <th>Word_c_years ago</th>\n",
       "      <th>Word_c_yes</th>\n",
       "      <th>Word_c_yield</th>\n",
       "      <th>Word_c_young</th>\n",
       "      <th>Word_c_zeal</th>\n",
       "      <th>Word_c_zealously</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1834 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word_c_abandon  Word_c_abiding  Word_c_ability  Word_c_able  Word_c_abroad  \\\n",
       "0               0               0               0            0              0   \n",
       "1               0               0               0            0              0   \n",
       "2               0               0               0            0              1   \n",
       "3               1               0               0            0              1   \n",
       "4               0               0               0            1              0   \n",
       "\n",
       "   Word_c_absolute  Word_c_abuse  Word_c_abuses  Word_c_accept  \\\n",
       "0                0             0              0              0   \n",
       "1                0             0              0              0   \n",
       "2                0             0              1              0   \n",
       "3                1             0              2              0   \n",
       "4                0             0              2              0   \n",
       "\n",
       "   Word_c_accepted  ...  Word_c_written  Word_c_wrong  Word_c_year  \\\n",
       "0                0  ...               0             0            0   \n",
       "1                0  ...               0             0            0   \n",
       "2                0  ...               0             0            2   \n",
       "3                0  ...               0             2            0   \n",
       "4                0  ...               1             0            2   \n",
       "\n",
       "   Word_c_years  Word_c_years ago  Word_c_yes  Word_c_yield  Word_c_young  \\\n",
       "0             0                 0           0             0             0   \n",
       "1             0                 0           0             0             0   \n",
       "2             3                 0           0             0             0   \n",
       "3             0                 0           0             0             0   \n",
       "4             2                 0           0             0             0   \n",
       "\n",
       "   Word_c_zeal  Word_c_zealously  \n",
       "0            0                 0  \n",
       "1            0                 0  \n",
       "2            1                 0  \n",
       "3            1                 0  \n",
       "4            3                 0  \n",
       "\n",
       "[5 rows x 1834 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_array, \n",
    "                     columns=cv.get_feature_names()).add_prefix('Word_c_')\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40405ef8",
   "metadata": {},
   "source": [
    "### 2- TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4d4a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\anaconda3\\envs\\IE\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TFIDF_abandon</th>\n",
       "      <th>TFIDF_abiding</th>\n",
       "      <th>TFIDF_ability</th>\n",
       "      <th>TFIDF_able</th>\n",
       "      <th>TFIDF_abroad</th>\n",
       "      <th>TFIDF_absolute</th>\n",
       "      <th>TFIDF_abuse</th>\n",
       "      <th>TFIDF_abuses</th>\n",
       "      <th>TFIDF_accept</th>\n",
       "      <th>TFIDF_accepted</th>\n",
       "      <th>...</th>\n",
       "      <th>TFIDF_written</th>\n",
       "      <th>TFIDF_wrong</th>\n",
       "      <th>TFIDF_year</th>\n",
       "      <th>TFIDF_years</th>\n",
       "      <th>TFIDF_years ago</th>\n",
       "      <th>TFIDF_yes</th>\n",
       "      <th>TFIDF_yield</th>\n",
       "      <th>TFIDF_young</th>\n",
       "      <th>TFIDF_zeal</th>\n",
       "      <th>TFIDF_zealously</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050920</td>\n",
       "      <td>0.049983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034461</td>\n",
       "      <td>0.046532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046532</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.033035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TFIDF_abandon  TFIDF_abiding  TFIDF_ability  TFIDF_able  TFIDF_abroad  \\\n",
       "0       0.000000            0.0            0.0    0.000000      0.000000   \n",
       "1       0.000000            0.0            0.0    0.000000      0.000000   \n",
       "2       0.000000            0.0            0.0    0.000000      0.027965   \n",
       "3       0.048435            0.0            0.0    0.000000      0.034461   \n",
       "4       0.000000            0.0            0.0    0.030796      0.000000   \n",
       "\n",
       "   TFIDF_absolute  TFIDF_abuse  TFIDF_abuses  TFIDF_accept  TFIDF_accepted  \\\n",
       "0        0.000000          0.0      0.000000           0.0             0.0   \n",
       "1        0.000000          0.0      0.000000           0.0             0.0   \n",
       "2        0.000000          0.0      0.036379           0.0             0.0   \n",
       "3        0.046532          0.0      0.089660           0.0             0.0   \n",
       "4        0.000000          0.0      0.072131           0.0             0.0   \n",
       "\n",
       "   ...  TFIDF_written  TFIDF_wrong  TFIDF_year  TFIDF_years  TFIDF_years ago  \\\n",
       "0  ...       0.000000     0.000000    0.000000     0.000000              0.0   \n",
       "1  ...       0.000000     0.000000    0.000000     0.000000              0.0   \n",
       "2  ...       0.000000     0.000000    0.050920     0.049983              0.0   \n",
       "3  ...       0.000000     0.065688    0.000000     0.000000              0.0   \n",
       "4  ...       0.034827     0.000000    0.050481     0.033035              0.0   \n",
       "\n",
       "   TFIDF_yes  TFIDF_yield  TFIDF_young  TFIDF_zeal  TFIDF_zealously  \n",
       "0        0.0          0.0          0.0    0.000000              0.0  \n",
       "1        0.0          0.0          0.0    0.000000              0.0  \n",
       "2        0.0          0.0          0.0    0.037761              0.0  \n",
       "3        0.0          0.0          0.0    0.046532              0.0  \n",
       "4        0.0          0.0          0.0    0.112304              0.0  \n",
       "\n",
       "[5 rows x 1821 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate TfidfVectorizer\n",
    "tv = TfidfVectorizer(stop_words='english',max_df=0.8,min_df=0.1,ngram_range=(1,3))\n",
    "#min_df : the minimum frequency of words in dataset\n",
    "#max_df : the maximum frequency of words in dataset\n",
    "#stop_words: words to ignore (defined above in post)\n",
    "#ngram_range: explained above\n",
    "# Fit the vectroizer and transform the data\n",
    "tv_transformed = tv.fit_transform(text_df['clean_text'])\n",
    "\n",
    "# Create a DataFrame with these features\n",
    "tv_df = pd.DataFrame(tv_transformed.toarray(), \n",
    "                     columns=tv.get_feature_names()).add_prefix('TFIDF_')\n",
    "tv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66b837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
